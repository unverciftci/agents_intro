{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJ99ujFMJyZwHE4zTueyzi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unverciftci/agents_intro/blob/main/N2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "ejcTDDhzNXJ2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDsoDGAVM1nn",
        "outputId": "05d69a6e-f447-4291-da66-da02c5f40816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading AI...\n",
            "‚úÖ AI ready!\n",
            "‚úÖ Tools ready: calculator, get_weather\n",
            "\n",
            "üß™ Testing agent with tools:\n",
            "\n",
            "--- Test ---\n",
            "üë§ User: What's 25 * 4?\n",
            "ü§ñ AI: I'll calculate that for you. TOOL:calculator:25*4\n",
            "üõ†Ô∏è Using tool: calculator(25*4)\n",
            "‚úÖ Tool result: Result: 100\n",
            "Final response: I'll calculate that for you. TOOL:calculator:25*4\n",
            "Tool result: Result: 100\n",
            "Result: 100\n",
            "----------------------------------------\n",
            "\n",
            "--- Test ---\n",
            "üë§ User: What's the weather in London?\n",
            "ü§ñ AI: I'll check the weather for you. TOOL:get_weather:london\n",
            "üõ†Ô∏è Using tool: get_weather(london)\n",
            "‚úÖ Tool result: Rainy, 15¬∞C\n",
            "Final response: I'll check the weather for you. TOOL:get_weather:london\n",
            "Tool result: Rainy, 15¬∞C\n",
            "The weather in London is **Rainy, 15¬∞C**.\n",
            "----------------------------------------\n",
            "\n",
            "--- Test ---\n",
            "üë§ User: Hello! How are you?\n",
            "ü§ñ AI: Hello! How can I help you today?\n",
            "Final response: Hello! How can I help you today?\n",
            "----------------------------------------\n",
            "\n",
            "--- Test ---\n",
            "üë§ User: Calculate 100 / 5 please\n",
            "ü§ñ AI: I'll calculate that for you. TOOL:calculator:100/5\n",
            "üõ†Ô∏è Using tool: calculator(100/5)\n",
            "‚úÖ Tool result: Result: 20.0\n",
            "Final response: I'll calculate that for you. TOOL:calculator:100/5\n",
            "Tool result: Result: 20.0\n",
            "Result: 20.0  \n",
            "Final response: 20.0\n",
            "----------------------------------------\n",
            "\n",
            "üéâ Your AI can now use tools!\n",
            "üöÄ Next: Tutorial 3 - Add memory\n"
          ]
        }
      ],
      "source": [
        "# Tutorial 2: AI with Tools\n",
        "# Goal: Transform chatbot into tool-using agent\n",
        "\n",
        "import re\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load AI (same as Tutorial 1)\n",
        "print(\"Loading AI...\")\n",
        "model_name = \"Qwen/Qwen3-0.6B\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "print(\"‚úÖ AI ready!\")\n",
        "\n",
        "# Step 1: Create tools\n",
        "def calculator(expression):\n",
        "    \"\"\"Simple calculator tool\"\"\"\n",
        "    try:\n",
        "        result = eval(expression)\n",
        "        return f\"Result: {result}\"\n",
        "    except:\n",
        "        return \"Error: Invalid calculation\"\n",
        "\n",
        "def get_weather(city):\n",
        "    \"\"\"Weather tool (simulated data)\"\"\"\n",
        "    weather_data = {\n",
        "        \"paris\": \"Sunny, 22¬∞C\",\n",
        "        \"london\": \"Rainy, 15¬∞C\",\n",
        "        \"tokyo\": \"Cloudy, 18¬∞C\",\n",
        "        \"new york\": \"Windy, 20¬∞C\"\n",
        "    }\n",
        "    return weather_data.get(city.lower(), \"Weather data not available\")\n",
        "\n",
        "# Tool registry\n",
        "TOOLS = {\n",
        "    \"calculator\": calculator,\n",
        "    \"get_weather\": get_weather\n",
        "}\n",
        "\n",
        "print(\"‚úÖ Tools ready: calculator, get_weather\")\n",
        "\n",
        "# Step 2: Basic AI function\n",
        "def ask_ai(prompt):\n",
        "    \"\"\"Send prompt to AI and get response\"\"\"\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True, enable_thinking=False\n",
        "    )\n",
        "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(\n",
        "            **model_inputs,\n",
        "            max_new_tokens=120,\n",
        "            temperature=0.3,\n",
        "            do_sample=True,\n",
        "        )\n",
        "\n",
        "    output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
        "    return tokenizer.decode(output_ids, skip_special_tokens=True).strip()\n",
        "\n",
        "# Step 3: Agent with tools\n",
        "def agent_with_tools(user_message):\n",
        "    \"\"\"AI agent that can use tools\"\"\"\n",
        "\n",
        "    # System prompt with examples\n",
        "    system_prompt = f\"\"\"You are an AI assistant that can use tools. When you need to:\n",
        "- Calculate something: use TOOL:calculator:expression\n",
        "- Get weather: use TOOL:get_weather:city\n",
        "\n",
        "Examples:\n",
        "User: What's 15 + 27?\n",
        "AI: I'll calculate that for you. TOOL:calculator:15+27\n",
        "\n",
        "User: What's the weather in Paris?\n",
        "AI: Let me check the weather. TOOL:get_weather:paris\n",
        "\n",
        "User: Hi there!\n",
        "AI: Hello! How can I help you today?\n",
        "\n",
        "User: {user_message}\n",
        "AI:\"\"\"\n",
        "\n",
        "    print(f\"üë§ User: {user_message}\")\n",
        "\n",
        "    # Get AI response\n",
        "    ai_response = ask_ai(system_prompt)\n",
        "    print(f\"ü§ñ AI: {ai_response}\")\n",
        "\n",
        "    # Check if AI wants to use a tool\n",
        "    if \"TOOL:\" in ai_response:\n",
        "        tool_match = re.search(r'TOOL:(\\w+):(.+)', ai_response)\n",
        "        if tool_match:\n",
        "            tool_name = tool_match.group(1)\n",
        "            tool_input = tool_match.group(2).strip()\n",
        "\n",
        "            print(f\"üõ†Ô∏è Using tool: {tool_name}({tool_input})\")\n",
        "\n",
        "            if tool_name in TOOLS:\n",
        "                tool_result = TOOLS[tool_name](tool_input)\n",
        "                print(f\"‚úÖ Tool result: {tool_result}\")\n",
        "\n",
        "                # Get final response with tool result\n",
        "                final_prompt = system_prompt + ai_response + f\"\\nTool result: {tool_result}\\nFinal response:\"\n",
        "                final_response = ask_ai(final_prompt)\n",
        "\n",
        "                return f\"{ai_response}\\nTool result: {tool_result}\\n{final_response}\"\n",
        "            else:\n",
        "                return f\"{ai_response}\\nError: Unknown tool '{tool_name}'\"\n",
        "\n",
        "    return ai_response\n",
        "\n",
        "# Step 4: Test the agent\n",
        "print(\"\\nüß™ Testing agent with tools:\")\n",
        "\n",
        "test_questions = [\n",
        "    \"What's 25 * 4?\",\n",
        "    \"What's the weather in London?\",\n",
        "    \"Hello! How are you?\",\n",
        "    \"Calculate 100 / 5 please\"\n",
        "]\n",
        "\n",
        "for question in test_questions:\n",
        "    print(f\"\\n--- Test ---\")\n",
        "    response = agent_with_tools(question)\n",
        "    print(f\"Final response: {response}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Step 5: Interactive mode\n",
        "def chat_with_agent():\n",
        "    \"\"\"Interactive chat with tool-using agent\"\"\"\n",
        "    print(\"\\nüõ†Ô∏è Chat with your agent (now with tools!)\")\n",
        "    print(\"Try asking for calculations or weather!\")\n",
        "    print(\"Type 'quit' to exit\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nüë§ You: \")\n",
        "\n",
        "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
        "            print(\"üëã Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if user_input.strip():\n",
        "            response = agent_with_tools(user_input)\n",
        "            print(f\"ü§ñ Final: {response}\")\n",
        "\n",
        "# Ready to test? Uncomment the line below:\n",
        "# chat_with_agent()\n",
        "\n",
        "print(\"\\nüéâ Your AI can now use tools!\")\n",
        "print(\"üöÄ Next: Tutorial 3 - Add memory\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GO04CgabNY00"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}