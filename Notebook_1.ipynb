{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNmbgdI/zomhzAzszHmC5Su",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unverciftci/agents_intro/blob/main/Notebook_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "VShysMK9E_fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial 1: Your First AI\n",
        "# Goal: Get AI running and understand basic interaction"
      ],
      "metadata": {
        "id": "gEutWneWGNgg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMQTwolLEkrW",
        "outputId": "dbdc9e83-982f-4ee4-fdaf-99433eed9559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading AI...\n",
            "âœ… AI ready!\n",
            "\n",
            "ğŸ§ª Testing your AI:\n",
            "\n",
            "ğŸ‘¤ You: Hello! What's your name?\n",
            "ğŸ¤– AI: Hello! My name is Liza. How can I assist you?\n",
            "\n",
            "ğŸ‘¤ You: What can you help me with?\n",
            "ğŸ¤– AI: Sure! What can I help you with right now? Let me know your needs!\n",
            "\n",
            "ğŸ‘¤ You: Tell me a fun fact\n",
            "ğŸ¤– AI: Fun fact: The number of letters in the word \"apple\" is 5, and the number of letters in the word \"banana\" is 6. But when you add these two numbers together, you get 11, which is the number of letters in the word \"applepie\". ğŸâœ¨\n",
            "\n",
            "ğŸ‰ Congratulations! You have a working AI!\n",
            "ğŸš€ Next: Tutorial 2 - Add tools to make it an agent\n"
          ]
        }
      ],
      "source": [
        "# Tutorial 1: Your First AI\n",
        "# Goal: Get AI running and understand basic interaction\n",
        "\n",
        "# Step 1: Install requirements\n",
        "!pip install transformers torch accelerate -q\n",
        "\n",
        "# Step 2: Import libraries\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Step 3: Load the AI model\n",
        "print(\"Loading AI...\")\n",
        "model_name = \"Qwen/Qwen3-0.6B\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "print(\"âœ… AI ready!\")\n",
        "\n",
        "# Step 4: Create the chat function\n",
        "def chat_with_ai(message):\n",
        "    \"\"\"Send a message to AI and get response\"\"\"\n",
        "\n",
        "    # Format as chat\n",
        "    messages = [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "    # Apply chat template\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "        enable_thinking=False\n",
        "    )\n",
        "\n",
        "    # Generate response\n",
        "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(\n",
        "            **model_inputs,\n",
        "            max_new_tokens=1000,\n",
        "            temperature=0.7,\n",
        "            do_sample=True\n",
        "        )\n",
        "\n",
        "    # Extract response\n",
        "    output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
        "    response = tokenizer.decode(output_ids, skip_special_tokens=True).strip()\n",
        "\n",
        "    return response\n",
        "\n",
        "# Step 5: Test your AI\n",
        "print(\"\\nğŸ§ª Testing your AI:\")\n",
        "\n",
        "test_messages = [\n",
        "    \"Hello! What's your name?\",\n",
        "    \"What can you help me with?\",\n",
        "    \"Tell me a fun fact\"\n",
        "]\n",
        "\n",
        "for message in test_messages:\n",
        "    print(f\"\\nğŸ‘¤ You: {message}\")\n",
        "    response = chat_with_ai(message)\n",
        "    print(f\"ğŸ¤– AI: {response}\")\n",
        "\n",
        "# Step 6: Interactive chat (optional)\n",
        "def start_chat():\n",
        "    \"\"\"Interactive chat with your AI\"\"\"\n",
        "    print(\"\\nğŸ’¬ Start chatting! Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        user_message = input(\"\\nğŸ‘¤ You: \")\n",
        "\n",
        "        if user_message.lower() in ['quit', 'exit', 'q']:\n",
        "            print(\"ğŸ‘‹ Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if user_message.strip():\n",
        "            ai_response = chat_with_ai(user_message)\n",
        "            print(f\"ğŸ¤– AI: {ai_response}\")\n",
        "\n",
        "# Ready to chat? Uncomment the line below:\n",
        "#start_chat()\n",
        "\n",
        "print(\"\\nğŸ‰ Congratulations! You have a working AI!\")\n",
        "print(\"ğŸš€ Next: Tutorial 2 - Add tools to make it an agent\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ready to chat? Uncomment the line below:\n",
        "# Type 'quit', 'exit' or 'q' to end conversation.\n",
        "start_chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmkpn0rREqVV",
        "outputId": "6350ea0b-858f-4773-de5f-2e4230a05614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ’¬ Start chatting! Type 'quit' to exit.\n",
            "\n",
            "ğŸ‘¤ You: q\n",
            "ğŸ‘‹ Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7y_y1odiFPa_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}